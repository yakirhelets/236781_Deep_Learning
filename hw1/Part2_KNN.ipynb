{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Nearest-neighbor classification\n",
    "<a id=part2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll familiarize ourselves with the `PyTorch` tensor API by implementing a very simple classifier,\n",
    "kNN, using efficient, vectorized tensor operations alone.\n",
    "We'll then implement cross-validation, an important ML technique used to find suitable\n",
    "values for a model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "torch.random.manual_seed(1904)\n",
    "test = unittest.TestCase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Classification\n",
    "<a id=part2_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably the most basic classification scheme in a supervised learning setting is the\n",
    "`k` nearest-neighbor (kNN) classifier.\n",
    "Given a training data set, kNN's \"training\" phase consists of simply **memorizing** it.\n",
    "When a classification of an unseen sample is required, some distance metric (e.g. euclidean)\n",
    "is computed from all training samples.\n",
    "The unseen sample is then classified according to the majority label of it's `k` nearest-neighbors.\n",
    "\n",
    "Here we'll implement the most basic kNN, working directly on image pixel values and computing L2 distance\n",
    "between a test image and every known training image.\n",
    "We'll use data from the [MNIST](http://yann.lecun.com/exdb/mnist/) database of handwritten digits.\n",
    "This database contains single-channel images with a constant black background and the digits are\n",
    "roughly the same size, which makes it feasible to obtain bearable classification accuracy even with\n",
    "such a na√Øve model.\n",
    "\n",
    "Note however that real-world KNN model are often implemented with tree-based data structures to\n",
    "find nearest neighbors in logarithmic time, specialized distance functions and\n",
    "using image features instead of raw pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `TensorView` transform in the `hw1/transforms` module, and run the following code to\n",
    "load the data we'll work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for kNN Classifier\n",
    "import torchvision.transforms as tvtf\n",
    "\n",
    "import cs236781.dataloader_utils as dataloader_utils\n",
    "import hw1.datasets as hw1datasets\n",
    "import hw1.transforms as hw1tf\n",
    "\n",
    "# Define the transforms that should be applied to each CIFAR-10 image before returning it\n",
    "tf_ds = tvtf.Compose([\n",
    "    tvtf.ToTensor(), # Convert PIL image to pytorch Tensor\n",
    "    hw1tf.TensorView(-1), # Reshape to 1D Tensor\n",
    "])\n",
    "\n",
    "# Define how much data to load (only use a subset for speed)\n",
    "num_train = 10000\n",
    "num_test = 1000\n",
    "batch_size = 1024\n",
    "\n",
    "# Training dataset & loader\n",
    "data_root = os.path.expanduser('~/.pytorch-datasets')\n",
    "ds_train = hw1datasets.SubsetDataset(\n",
    "    torchvision.datasets.MNIST(root=data_root, download=True, train=True, transform=tf_ds), num_train)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size)\n",
    "\n",
    "# Test dataset & loader\n",
    "ds_test = hw1datasets.SubsetDataset(\n",
    "    torchvision.datasets.MNIST(root=data_root, download=True, train=False, transform=tf_ds), num_test)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size)\n",
    "\n",
    "# Get all test data\n",
    "x_test, y_test = dataloader_utils.flatten(dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `l2_dist` function in the `hw1/knn_classifier.py` module. This is the core of the kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import hw1.knn_classifier as hw1knn\n",
    "\n",
    "def l2_dist_naive(x1, x2):\n",
    "    \"\"\"\n",
    "    Naive distance calculation, just for testing.\n",
    "    Super slow, don't use!\n",
    "    \"\"\"\n",
    "    dists = torch.empty(x1.shape[0], x2.shape[0], dtype=torch.float)\n",
    "    for i, j in it.product(range(x1.shape[0]), range(x2.shape[0])):\n",
    "        dists[i,j] = torch.sum((x1[i] - x2[j])**2).item()\n",
    "    return torch.sqrt(dists)\n",
    "\n",
    "\n",
    "# Test distance calculation\n",
    "x1 = torch.randn(12, 34)\n",
    "x2 = torch.randn(45, 34)\n",
    "\n",
    "dists = hw1knn.l2_dist(x1, x2)\n",
    "dists_naive = l2_dist_naive(x1, x2)\n",
    "\n",
    "test.assertTrue(torch.allclose(dists, dists_naive), msg=\"Wrong distances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `accuracy` function in the `hw1/knn_classifier.py` module.\n",
    "This will be our score. It will simply return the fraction of predictions that are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.tensor([0, 1, 2, 3])\n",
    "y2 = torch.tensor([2, 2, 2, 2])\n",
    "\n",
    "test.assertEqual(hw1knn.accuracy(y1, y2), 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Complete the implementation of the `KNNClassifier` class in the module `hw1/knn_classifier.py`:\n",
    "1. Implement the kNN \"training\" in the `train()` method.\n",
    "1. Implement label prediction in the `predict()` method.\n",
    "\n",
    "Use the following code to test your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.50%\n"
     ]
    }
   ],
   "source": [
    "# Test kNN Classifier\n",
    "knn_classifier = hw1knn.KNNClassifier(k=10)\n",
    "knn_classifier.train(dl_train)\n",
    "y_pred = knn_classifier.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = hw1knn.accuracy(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Sanity check: at least 80% accuracy\n",
    "test.assertGreater(accuracy, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "<a id=part2_2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to  choose hyperparameters for a model or even the model itself is by applying\n",
    "**K-fold cross-validation** (CV).\n",
    "For each candidate set of hyperparameters, the model is trained `K` times, each time with a different split of the training data to train and validation sets (called a fold). The set of hyperparameters which resulted in the the lowest average validation error rate is selected.\n",
    "\n",
    "More specifically, K-fold CV is usually performed as follows:\n",
    "\n",
    "1. For all choices of a model and/or set of hyperparameters for the model:\n",
    "    1. Split training set into `K` non-overlapping parts. \n",
    "    1. For `k=0,...,K-1`:\n",
    "        1. Select the `k`-th part as the validation set and the remaining `k-1` parts as the training set.\n",
    "        1. Train the current model on the current training set.\n",
    "        1. Evaluate the model on the current validation set to obtain it's validation error.\n",
    "    1. Calculate current model's average validation error accross the K folds.\n",
    "1. Select the model with the lowest average validation error.\n",
    "1. Train the selected model with the entire training set.\n",
    "1. Evaluate the model with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to find the best value of K for applying our kNN model to CIFAR-10.\n",
    "In this case we already fixed the model and there is only one hyperparameter, the value of `k`\n",
    "(not to be confused with `K`, the number of folds for the cross validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Complete the implementation of the `find_best_k` function in the `knn_classifier.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hw1.datasets.SubsetDataset object at 0x1237770d0>\n",
      "[1, 3, 5, 8, 12, 20, 50]\n",
      "4\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1a2d9252d0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 257, in __getitem__\n    return self.dataset[self.indices[idx]]\nTypeError: list indices must be integers or slices, not tuple\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ba48636445a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhw1knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_best_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_choices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Technion/SemesterFinale/Meitzim/HW/236781_Deep_Learning/hw1/hw1/knn_classifier.py\u001b[0m in \u001b[0;36mfind_best_k\u001b[0;34m(ds_train, k_choices, num_folds)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m#   train on all parts except j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m#   test on part j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Technion/SemesterFinale/Meitzim/HW/236781_Deep_Learning/hw1/hw1/knn_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dl_train)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# while (next_tuple != None):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#     print(next_tuple)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 257, in __getitem__\n    return self.dataset[self.indices[idx]]\nTypeError: list indices must be integers or slices, not tuple\n"
     ]
    }
   ],
   "source": [
    "num_folds = 4\n",
    "k_choices = [1, 3, 5, 8, 12, 20, 50]\n",
    "\n",
    "# Run cross-validation\n",
    "best_k, accuracies = hw1knn.find_best_k(ds_train, k_choices, num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x122a51710>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Users/GalFleissig/anaconda3/envs/cs236781-hw/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3fdcdf880109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_choices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_choices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcurr_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracies' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracies per k\n",
    "_, ax = plt.subplots(figsize=(12,6), subplot_kw=dict(xticks=k_choices))\n",
    "for i, k in enumerate(k_choices):\n",
    "    curr_accuracies = accuracies[i]\n",
    "    ax.scatter([k] * len(curr_accuracies), curr_accuracies)\n",
    "\n",
    "accuracies_mean = np.array([np.mean(accs) for accs in accuracies])\n",
    "accuracies_std = np.array([np.std(accs) for accs in accuracies])\n",
    "ax.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "ax.set_title(f'{num_folds}-fold Cross-validation on k')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "print('best_k =', best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we found our `best_k`, we can train the model with that value of `k` on the full training set and evaluate the accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = hw1knn.KNNClassifier(k=best_k)\n",
    "knn_classifier.train(dl_train)\n",
    "y_pred = knn_classifier.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_best_k = hw1knn.accuracy(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy_best_k*100:.2f}%')\n",
    "\n",
    "test.assertGreater(accuracy_best_k, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "**TODO** Answer the following questions. Write your answers in the appropriate variables in the module `hw1/answers.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs236781.answers import display_answer\n",
    "import hw1.answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "Does increasing `k` lead to improved generalization for unseen data? Why or why not? Up to what point? Think about the extremal values of `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Your answer:**\n",
       "Increasing ```k``` leads to improved generalization for unseen data up to a certain point. Large values of ```k```\n",
       "(up to the largest number which is the size of the dataset) will determine the class of the unseen\n",
       "data according to most of the examples in the dataset (in extreme values), which will be incorrect\n",
       "classification if the correct class is smaller in size. However, a value of ```k``` that is too small might\n",
       "also be incorrect if the closest example belongs to the incorrect class (which can happen if the number\n",
       "of examples is too small). Therefore the ideal value of ```k``` should be neither too small nor too large.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_answer(hw1.answers.part2_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "Explain why (i.e. in what sense) using k-fold CV, as detailed above, is better than:\n",
    "1. Training on the entire train-set with various models and selecting the best model with respect to **train-set** accuracy.\n",
    "2. Training on the entire train-set with various models and selecting the best model with respect to **test-set** accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Your answer:**\n",
       "1. Training on the entire train-set with various models and then selecting the best model with respect\n",
       "to train-set accuracy is bad practice, since it leads to overfitting on the training data. We will then select\n",
       "a model that performs best on the training data, while it may very well be very wrong on new unseen data.\n",
       "\n",
       "2. Training on the entire train-set with various models and then selecting the best model with respect\n",
       "to test-set accuracy is somewhat better than (1), since we are determining the selected model according to\n",
       "untouched test-set. However, the selected model is very much influenced by the selected test set.\n",
       "Dividing the data differently might lead to completely different and inconsistent results.\n",
       "\n",
       "Using K-fold CV solves both problems. Overfitting is reduced a lot with K-fold CV since the selected model\n",
       "is determined by an average of the accuracy on different train-sets (each time a new train-set is selected),\n",
       "and the model is not biased towards one selected train-set.\n",
       "In addition, the selected model is not influenced by one test-set, since each time the model is being tested\n",
       "on a different test-set, which leads to consistent results and lack of bias.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_answer(hw1.answers.part2_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
